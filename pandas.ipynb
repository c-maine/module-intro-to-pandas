{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy: NUMerical PYthon \n",
    "\n",
    "This is Python's stack for scientific computing. The fundamental new data type is that of a **numpy array**, Python's matrix(tensor)-type object, which is used in the majority of Python's modules for Data Analysis, Statistics and Machine Learning  - for example in order to feed data into `sklearn` functions\n",
    "\n",
    "numpy arrays contain data all of the same type (*dtype*), numerical of many types or boolean\n",
    "\n",
    "The coordinates are known as axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create an array we use the np.array() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an array\n",
    "a = np.array([[1, 2, 3, 4, 5, 6], \n",
    "              [42, 53, 43 ,62, 7, 4], \n",
    "              [-3, -1, -4 ,-8, -52, -4], \n",
    "              [10, 0, 4 , 1, 0, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the elements in an array using multi-index notation, familiar in small variations in many computing environments and languages - with the usual Pythonic conventions, e.g., counting starts from 0, slicing a:b is inclusive:exclusive, negative indices, etc\n",
    "\n",
    "What do you think the following piece of code does? \n",
    "\n",
    "```python\n",
    "print(a[-2:,[2,4]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array attributes\n",
    "\n",
    "The array data type has its own attributes. Some worth highlighting are:\n",
    "\n",
    "+ Shape\n",
    "```python\n",
    "arrayname.shape # returns the shape as tuple, e.g. (4,6)\n",
    "arrayname.reshape(arg) # returns a new array with the same data as those in arrayname but organized in different shape - read carefully defaults\n",
    "```\n",
    "+ Aggregations\n",
    "```python\n",
    "arrayname.function(arg) # e.g. function could be sum, max, min, etc. args can be used to specify operation over all elements, or for an axis, etc  - this is much more efficient than looping\n",
    "```\n",
    "+ Linear algebra\n",
    "```python\n",
    "arrayname.transpose(arg)  # transpose - even for multi-d arrays\n",
    "arrayname.diagonal(arg) # diagonal elements as array\n",
    "arrayname.dot(anotherarray) # dot product\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array operations\n",
    "\n",
    "Remember that to concatenate two lists in Python, we could use the \"+\" operator. \n",
    "\n",
    "This is not the case in Numpy!\n",
    "\n",
    "Mathematical symbols take on mathematical meanings in Numpy. Thus, the \"+\" operator between two Numpy Arrays actually just attempts to add them together, elementwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7, 9])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy array addition: \n",
    "\n",
    "a,b = np.array([1,2,3]), np.array([4,5,6])\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy array concatenation: \n",
    "\n",
    "np.concatenate([a,b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data analysis with Python\n",
    "\n",
    "PANDAS: Panel Data Structures \n",
    "\n",
    "This is the module in Python for doing rectangular-data management, analysis and plotting.\n",
    "\n",
    "The first set of tools are to read and write. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading data into Python \n",
    "\n",
    "<img src=\"io_tools.png\"> \n",
    "\n",
    "See [IO DOC](https://pandas.pydata.org/pandas-docs/stable/io.html) in Python for more information\n",
    "\n",
    "Lets load our first dataset (and load all we need to get working!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load a dataframe from disk\n",
    "tips = pd.read_csv(\"tips.csv\")\n",
    "tips.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Series and DataFrame\n",
    "\n",
    "These are the two basic data formats in PANDAS, the equivalent of column and rectangular data structures, as in linear algebra (vector/matrix) but equipped with several attributes invaluable for data management and analysis\n",
    "\n",
    "In the *tips* example, the variable \"tips\" is a DataFrame, while any individual column would be a Series. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Series \n",
    "\n",
    "This is a 1-d data structure with *values* accessed via their index. \n",
    "\n",
    "Unlike in raw Python or Numpy, however, Series indices can be made up of either: \n",
    "+ *numbers*: which could be ordered and contiguous like a Python list, but don't have to be! \n",
    "+ *strings*: essentially labels, like the keys in a dictionary\n",
    "\n",
    "Although typically a series is obtained by reading a dataset from an external file or when doing operations on dataframes, we can still define one manually by specifying the values and the indices. \n",
    "\n",
    "Let's do this an get an insight into how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here no indices are specified, there are defaults\n",
    "my_series = pd.Series([1, 15, -5, None, 4, 123, 0, 78, 0, 5, -4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing a certain value via the index\n",
    "\n",
    "my_series[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that there are a bunch of attributes.\n",
    "# .values returns a numpy ndarray of the values! \n",
    "\n",
    "my_series.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the index. What type is it? \n",
    "# You convert itto a numpy ndarray by adding \".values\" again!\n",
    "\n",
    "my_series.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can overwrite the index directly: \n",
    "\n",
    "my_series.index = [\"om\",\"ir\",\"os\",\"pap\",\"pas\",\"pil\",\"io\",\"po\",\"ulos\",\"is\",\"best\"]\n",
    "\n",
    "my_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iloc\n",
    "\n",
    "Accessing values via the index can be very useful, but sometimes you want to access the values as though they were a Python list. In other words \"I want the first value!\", without having to know the name of the label. \n",
    "\n",
    "This can be achieved with .iloc: \n",
    "\n",
    "```python\n",
    "my_series.iloc[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series that have string indices can also be accessed via a RangeIndex\n",
    "# (which is similar to the index of a regular Python list)\n",
    "\n",
    "my_series.iloc[0], my_series[\"om\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_series' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-670b72a32bb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# This just resets the index to be as we found it originally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmy_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_series\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_series\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_series' is not defined"
     ]
    }
   ],
   "source": [
    "# Note that indices can get moved around, by sorting for example!\n",
    "# iloc gives you the element you would get if the Series\n",
    "# was a list and you were giving it the index:\n",
    "\n",
    "# This just resets the index to be as we found it originally\n",
    "my_series = my_series.reset_index(drop=True)\n",
    "\n",
    "x = my_series.sort_values()\n",
    "\n",
    "x[0], x.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Operations with series\n",
    "\n",
    "Because Series are Numpy arrays behind the scenes, we can compute element-wise functions on one series or several series at the same time. The result is another series with data type depending on the type of operations performed. \n",
    "\n",
    "For example, what do you think the following piece of code will do: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Series1 = pd.Series([1,3,5,7])\n",
    "Series2 = pd.Series([0,10,-1,6])\n",
    "\n",
    "Series3 = 2*Series1 + abs(Series2)\n",
    "\n",
    "Series4 = Series1 > Series2 \n",
    "\n",
    "#This is a boolean series. \n",
    "#When a numpy array adds 2 things, it adds them by the index. The index is always in order.\n",
    "#When a panda array adds 2 things, it adds them by the index. Note that this index might not necessarily be in order!\n",
    "\n",
    "# Take a look at the different Series objects!\n",
    "\n",
    "Series4 > Series3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data alignment \n",
    "\n",
    "What goes on in the previous examples is more subtle than it looks. How does Python know which elements from each series to join in the required operation together?  \n",
    "\n",
    "What happens is that the indices happened to be the same. So when we ask something like \n",
    "\n",
    "```python\n",
    "Series3 = Series1 + Series2 \n",
    "```\n",
    "\n",
    "Python looks for entries in each series with the same index and then does an elementwise summation that it stores in a like-wise index in Series 3. \n",
    "\n",
    "Consider instead the following example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Defining a module pd as part of the Series class with parameters 1,2,3\n",
    "#Could also do from pandas import Series, then use series without pd.\n",
    "my_series = pd.Series([1,2,3])\n",
    "\n",
    "#This code creates Series in pandas with index index\n",
    "Series1 = pd.Series([1,10],index=[\"om\",\"iros\"])\n",
    "Series2 = pd.Series([4,-1],index=[\"pap\",\"as\"])\n",
    "Series3 = Series1 + Series2\n",
    "\n",
    "#You could also create a dictionary and name that like this:\n",
    "#Series1 = {\"om\":1, \"iros\":2}\n",
    "\n",
    "np.isnan(Series3.iloc[0])\n",
    "#nan stands for not a number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This aspect makes it very easy to work with series that we have sorted or manipulated otherwise; there is always the address to access a value. This helps prevent accidentally combining values we didn't mean to combine!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic information retrieval with series\n",
    "\n",
    "+ Accessing single elements\n",
    "+ Slicing; accessing a set of elements\n",
    "+ Filtering; selection by  boolean index\n",
    "\n",
    "Recalling that operations on Series returns Series, the big news here is that we can access values in a Series by specifying \n",
    "\n",
    "+ single index\n",
    "+ a slice (a:b for integers a,b) \n",
    "+ list (or Numpy Array or Series) of index labels\n",
    "+ a boolean Series (also called a _boolean mask_) \n",
    "\n",
    "Interesting: the result of any such retrieval (except for a single index) is a series itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 3 elements, new values have 11 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6c2ca8c4e5dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# accesing by list of index labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmy_series\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"om\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ir\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"os\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"pap\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"pas\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"pil\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"io\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"po\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ulos\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"is\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"best\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_series\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"om\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"pap\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5191\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5192\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5193\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5194\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels, fastpath)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_index\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_subtyp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_all_dates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    181\u001b[0m             raise ValueError(\n\u001b[1;32m    182\u001b[0m                 \u001b[0;34m\"Length mismatch: Expected axis has {old} elements, new \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0;34m\"values have {new} elements\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mold_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             )\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 3 elements, new values have 11 elements"
     ]
    }
   ],
   "source": [
    "# accesing by list of index labels\n",
    "\n",
    "my_series.index = [\"om\",\"ir\",\"os\",\"pap\",\"pas\",\"pil\",\"io\",\"po\",\"ulos\",\"is\",\"best\"]\n",
    "x = my_series[[\"om\",\"pap\"]]\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting a boolean-valued series by checking a condition\n",
    "\n",
    "choose = my_series == 0.0\n",
    "choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the index of x is a SUBSET of the index of \"my_series\"\n",
    "# This can be useful when needing to relate values back to the original \"my_series\"!\n",
    "\n",
    "x = my_series[choose]\n",
    "#The following line of code is how you apply a filter in panda\n",
    "my_series[my_series == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering via boolean masks\n",
    "\n",
    "We often use boolean masks to filter data in Pandas. Series that are of type \"bool\" thus take on special significance: we use them a lot!\n",
    "\n",
    "We also get special boolean algebra operators to use in Numpy/Pandas, distinct from the and/or/not you will use in regular Python: \n",
    "\n",
    "\n",
    "```python\n",
    "& # AND\n",
    "| # OR\n",
    "~ # NOT\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.0\n",
       "1      15.0\n",
       "2      -5.0\n",
       "4       4.0\n",
       "5     123.0\n",
       "6       0.0\n",
       "7      78.0\n",
       "8       0.0\n",
       "9       5.0\n",
       "10     -4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Challenge: \n",
    "\n",
    "# Filter \"my_series\" to be all the elements that are NOT\n",
    "# equal to 0, using the \"choose\" boolean mask below: \n",
    "\n",
    "choose = my_series == 0.0\n",
    "\n",
    "my_series[~choose]\n",
    "\n",
    "my_series[(my_series < 10)| (my_series > 0)]\n",
    "\n",
    "#choose | choose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Coding and managing missing values\n",
    "\n",
    "A series object in PANDAS can deal with maybe the most important type of data of all for data analysis: missing data! \n",
    "\n",
    "We already see very naturally how data management leads to missing data rather immediately. Recall the earlier attempt to sum up to Series\n",
    "\n",
    "```python\n",
    "Series3 = Series1+Series2\n",
    "print(Series3)\n",
    "as     NaN\n",
    "iros   NaN\n",
    "om     NaN\n",
    "pap    NaN\n",
    "dtype: float64\n",
    "```\n",
    "What happened there is that in the operation labels could not be matched, so pandas tried to sum a numeric value with a missing value, the result of which is a missing value!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The way to manually specify in PANDAS that a value is missing is to use use None, as below: \n",
    "\n",
    "```python\n",
    "temp = pd.Series([1,None,2])\n",
    "print(temp)\n",
    "0    1.0\n",
    "1    NaN\n",
    "2    2.0\n",
    "dtype: float64\n",
    "```\n",
    "If the Series is numeric, Pandas will caste it to numpy.float64 type and convert the None values to Numpy NaN values (Not a Number). If the Series is of type \"object\" (arbitrary Python objects), it will keep the values as None.\n",
    "\n",
    "We can create *boolean masks* on the basis of such values. The way to identify NaN or None values in a Series is to use either of the equivalent two attributes\n",
    "\n",
    "```python\n",
    "seriesname.isna()\n",
    "seriesname.isnull()\n",
    "```\n",
    "\n",
    "Either returns a boolean-valued series that we can use then for selecting and operating on NaN or the rest of the values. The opposite also exists: \n",
    "\n",
    "```python\n",
    "seriesname.notna()\n",
    "seriesname.notnull()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    foo\n",
       "1    bar\n",
       "3    baz\n",
       "4    qux\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Challenge: \n",
    "# Get a list of names, without the Null values!\n",
    "\n",
    "# The Pandas way: \n",
    "# 1. Create a boolean mask by using the .notna() method.\n",
    "# 2. Use the mask to subset the Series.\n",
    "\n",
    "names = pd.Series(['foo','bar',None,'baz','qux',None])\n",
    "#Create a filter\n",
    "null_filter = names.notna()\n",
    "#Apply filter to pd.Series\n",
    "names[null_filter]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Highlighting some important series attributes & methods\n",
    "\n",
    "As usual one should explore the attributes of any python object one ends up working with. We have already accessed the seriesname.index and seriesname.value\n",
    "\n",
    "Some other (among many!) that are worth highlighting: \n",
    "\n",
    "+ .map\n",
    "+ .corr \n",
    "+ .describe\n",
    "+ .hist\n",
    "+ .plot\n",
    "+ .size\n",
    "+ .value_counts\n",
    "+ .sort_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     foo\n",
       "1     bar\n",
       "2    None\n",
       "3     foo\n",
       "4    None\n",
       "5     bar\n",
       "6     bar\n",
       "7     foo\n",
       "8    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Challenge: \n",
    "\n",
    "# Use the \"map\" method to create a new series with each element\n",
    "# lowercased. Create your own function to do the operation. \n",
    "# Missing values should stay missing!\n",
    "\n",
    "#This allows you to write code for a single element within a (list, array etc) and then apply it to all elements.\n",
    "#This is an alternative to the loops\n",
    "\n",
    "def lower(s):\n",
    "    try:\n",
    "        return s.lower()\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "\n",
    "names = pd.Series(['Foo', 'BAR', None, 'foo', None, 'bar', 'bAR', 'foo', None])\n",
    "\n",
    "names.map(lower)\n",
    "\n",
    "\n",
    "#To do this in loops\n",
    "#for i in names:\n",
    "    #print(lower(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge: \n",
    "\n",
    "# Using the series from above, now lowercased, count the occurences of each name\n",
    "# Hint: It's simple, just use .value_counts()!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataframes\n",
    "\n",
    "This is PANDAS model for rectangular data, operationally is like a dictionary of series; each column of the dataframe is a series object, and clearly comes with all the attributes/methods of a series\n",
    "\n",
    "An implication of the above is that within each column the data type is common; across columns of course this can change\n",
    "\n",
    "Let's see an example right away "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = pd.read_csv(\"tips.csv\")\n",
    "tips.head(10) # the first method of our dataframe object! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the other important attribute: name of rows and columns\n",
    "tips.index\n",
    "tips.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Accessing the series embedded within\n",
    "\n",
    "There are two way to access the information in the columns: \n",
    "+ One is to give the name of the column as `dataframename.columnname` \n",
    "   + This is not feasible when the name of the column coincides with an attribute or method of the dataframe, e.g. when a column is called \"size\"  \n",
    "+ Another is as dataframename[\"columnname\"]\n",
    "\n",
    "Any of these calls returns a series object with the same index as the dataframe and the values of the column\n",
    "\n",
    "We can then work with the extracted series as usual. Hence you can understand what happens below \n",
    "\n",
    "```python\n",
    "tips[\"size\"].corr(tips.tip)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In a similar fashion, we can access various columns at a time; we need to provide a list of column names in this case; the result is now a dataframe with the same index as the original and columns the chosen subset. We can then work with it using any of the dataframe attributes and methods we know. \n",
    "\n",
    "You can now guess what will happen below: \n",
    "\n",
    "```python\n",
    "tips[[\"tip\",\"size\",\"sex\"]].tip.corr(tips[\"size\"])\n",
    "\n",
    "```\n",
    "(not saying that this is a sensible code! just trying to make sure we understand the structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Accessing subsets of rows\n",
    "\n",
    "Now we are interested in a subset of rows. We can access rows by:\n",
    "+ list of index labels \n",
    "  ```python\n",
    "  dataframename.loc[ [index1, index2, ...] ]\n",
    "  ```\n",
    "+ list of integer index location (i-loc) \n",
    "  ```python\n",
    "  dataframename.iloc[ [integer1, integer2, ...] ]\n",
    "  ```\n",
    "The output is:\n",
    "+ a series, if a single column or row is chosen\n",
    "+ a dataframe, with index label the chosen index labels and the same column names as the dataframe\n",
    "\n",
    "In the case of .iloc we can also use slices, as for example\n",
    "```python\n",
    "dataframename.iloc[3:5]\n",
    "dataframename.iloc[3:5,:]\n",
    "dataframename.iloc[3:5,-2:]\n",
    "```\n",
    "\n",
    "Note: loc/iloc are also used to access a subset of rows AND columns at the same time. See examples below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing rows AND columns!\n",
    "# Example of 2-dimension loc\n",
    "\n",
    "tips.loc[[1,3], ['sex', 'smoker']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing rows AND columns!\n",
    "# Example of 2-dimensional iloc\n",
    "\n",
    "tips.iloc[[1,3], 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge:\n",
    "\n",
    "# Using the tips dataframe, create a new one that contains the \n",
    "# information contained in all rows between the 20th (inclusive) \n",
    "# and the 45th (exclusive) and only the columns: tip, sex, day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that certain operations are exchangeable: the 3rd element of column \"sex\" can be obtained with either of the following ways: \n",
    "```python\n",
    "tips.sex[2] #access col as series, then the 3rd element of that\n",
    "tips.loc[2,\"sex\"] #access the entry in dataframe by giving the index labels of row and col (recall here index labels coincide with numerical indices\n",
    "tips.loc[2][\"sex\"] #accessing the whole row as a series, then using the column name as index label\n",
    "```\n",
    "etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Filtering\n",
    "\n",
    "As with series, we can use a boolean-valued series to index a dataframe provided the share the same index labels. The simplest instance of this is to use series produced as boolean masks of columns of the dataframe. The output of this *filtering* operation is a dataframe with subset of rows corresponding to the True values in the boolean mask. \n",
    "\n",
    "For example, for the tips data, what does the following produce? \n",
    "```python\n",
    "tips[tips.sex == \"Male\"] \n",
    "```\n",
    "\n",
    "Recall that the boolean operators are \n",
    "```python\n",
    "& # AND\n",
    "| # OR\n",
    "~ # NOT\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistics and computations\n",
    "\n",
    "dataframe comes with several attributes for computing column-wise statistics and summaries. We highlight some \n",
    "```python\n",
    ".boxplot # check out the \"by = \" option!\n",
    ".corrwith & .corr # within and across dataframes!\n",
    ".dot \n",
    ".mean/median/max/quantile/sum etc\n",
    ".sample \n",
    ".sort_values \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tip</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tip</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.404632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>size</td>\n",
       "      <td>0.404632</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tip      size\n",
       "tip   1.000000  0.404632\n",
       "size  0.404632  1.000000"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Challenge:\n",
    "\n",
    "# Using the tips dataframe, calculate the correlation between\n",
    "# tip and size for only Male clients during Dinner. \n",
    "\n",
    "# HINT: Remember that \"size\" cannot be accessed via dot notation, as it's an \n",
    "# attribute of the series!\n",
    "\n",
    "\n",
    "#tips is the file, [] selects an index filtering on the columns of time for dinner and sex for male\n",
    "#Then to find correlation, choose the 2 variables we are looking for\n",
    "\n",
    "t = tips[(tips.time==\"Dinner\") &(tips.sex==\"Male\")][[\"tip\",\"size\"]].corr()\n",
    "t['size'].corrit(t.tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GroupBy\n",
    "\n",
    "This dataframe method groups the dataframe according to the values of a column, treating them as categorical values; it returns a groupby object!\n",
    "\n",
    "Groupby objects are useful, but can feel a bit opaque. Let's play around with them a bit: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,      total_bill   tip     sex smoker   day    time  size\n",
       "  67         3.07  1.00  Female    Yes   Sat  Dinner     1\n",
       "  82        10.07  1.83  Female     No  Thur   Lunch     1\n",
       "  111        7.25  1.00  Female     No   Sat  Dinner     1\n",
       "  222        8.58  1.92    Male    Yes   Fri   Lunch     1),\n",
       " (2,      total_bill   tip     sex smoker   day    time  size\n",
       "  0         16.99  1.01  Female     No   Sun  Dinner     2\n",
       "  3         23.68  3.31    Male     No   Sun  Dinner     2\n",
       "  6          8.77  2.00    Male     No   Sun  Dinner     2\n",
       "  8         15.04  1.96    Male     No   Sun  Dinner     2\n",
       "  9         14.78  3.23    Male     No   Sun  Dinner     2\n",
       "  ..          ...   ...     ...    ...   ...     ...   ...\n",
       "  237       32.83  1.17    Male    Yes   Sat  Dinner     2\n",
       "  240       27.18  2.00  Female    Yes   Sat  Dinner     2\n",
       "  241       22.67  2.00    Male    Yes   Sat  Dinner     2\n",
       "  242       17.82  1.75    Male     No   Sat  Dinner     2\n",
       "  243       18.78  3.00  Female     No  Thur  Dinner     2\n",
       "  \n",
       "  [156 rows x 7 columns]),\n",
       " (3,      total_bill    tip     sex smoker   day    time  size\n",
       "  1         10.34   1.66    Male     No   Sun  Dinner     3\n",
       "  2         21.01   3.50    Male     No   Sun  Dinner     3\n",
       "  16        10.33   1.67  Female     No   Sun  Dinner     3\n",
       "  17        16.29   3.71    Male     No   Sun  Dinner     3\n",
       "  18        16.97   3.50  Female     No   Sun  Dinner     3\n",
       "  19        20.65   3.35    Male     No   Sat  Dinner     3\n",
       "  35        24.06   3.60    Male     No   Sat  Dinner     3\n",
       "  36        16.31   2.00    Male     No   Sat  Dinner     3\n",
       "  37        16.93   3.07  Female     No   Sat  Dinner     3\n",
       "  38        18.69   2.31    Male     No   Sat  Dinner     3\n",
       "  39        31.27   5.00    Male     No   Sat  Dinner     3\n",
       "  40        16.04   2.24    Male     No   Sat  Dinner     3\n",
       "  48        28.55   2.05    Male     No   Sun  Dinner     3\n",
       "  64        17.59   2.64    Male     No   Sat  Dinner     3\n",
       "  65        20.08   3.15    Male     No   Sat  Dinner     3\n",
       "  71        17.07   3.00  Female     No   Sat  Dinner     3\n",
       "  102       44.30   2.50  Female    Yes   Sat  Dinner     3\n",
       "  112       38.07   4.00    Male     No   Sun  Dinner     3\n",
       "  114       25.71   4.00  Female     No   Sun  Dinner     3\n",
       "  129       22.82   2.18    Male     No  Thur   Lunch     3\n",
       "  146       18.64   1.36  Female     No  Thur   Lunch     3\n",
       "  152       17.26   2.74    Male     No   Sun  Dinner     3\n",
       "  162       16.21   2.00  Female     No   Sun  Dinner     3\n",
       "  165       24.52   3.48    Male     No   Sun  Dinner     3\n",
       "  170       50.81  10.00    Male    Yes   Sat  Dinner     3\n",
       "  182       45.35   3.50    Male    Yes   Sun  Dinner     3\n",
       "  186       20.90   3.50  Female    Yes   Sun  Dinner     3\n",
       "  188       18.15   3.50  Female    Yes   Sun  Dinner     3\n",
       "  189       23.10   4.00    Male    Yes   Sun  Dinner     3\n",
       "  200       18.71   4.00    Male    Yes  Thur   Lunch     3\n",
       "  205       16.47   3.23  Female    Yes  Thur   Lunch     3\n",
       "  206       26.59   3.41    Male    Yes   Sat  Dinner     3\n",
       "  210       30.06   2.00    Male    Yes   Sat  Dinner     3\n",
       "  214       28.17   6.50  Female    Yes   Sat  Dinner     3\n",
       "  223       15.98   3.00  Female     No   Fri   Lunch     3\n",
       "  231       15.69   3.00    Male    Yes   Sat  Dinner     3\n",
       "  238       35.83   4.67  Female     No   Sat  Dinner     3\n",
       "  239       29.03   5.92    Male     No   Sat  Dinner     3),\n",
       " (4,      total_bill   tip     sex smoker   day    time  size\n",
       "  4         24.59  3.61  Female     No   Sun  Dinner     4\n",
       "  5         25.29  4.71    Male     No   Sun  Dinner     4\n",
       "  7         26.88  3.12    Male     No   Sun  Dinner     4\n",
       "  11        35.26  5.00  Female     No   Sun  Dinner     4\n",
       "  13        18.43  3.00    Male     No   Sun  Dinner     4\n",
       "  23        39.42  7.58    Male     No   Sat  Dinner     4\n",
       "  25        17.81  2.34    Male     No   Sat  Dinner     4\n",
       "  31        18.35  2.50    Male     No   Sat  Dinner     4\n",
       "  33        20.69  2.45  Female     No   Sat  Dinner     4\n",
       "  44        30.40  5.60    Male     No   Sun  Dinner     4\n",
       "  47        32.40  6.00    Male     No   Sun  Dinner     4\n",
       "  52        34.81  5.20  Female     No   Sun  Dinner     4\n",
       "  54        25.56  4.34    Male     No   Sun  Dinner     4\n",
       "  56        38.01  3.00    Male    Yes   Sat  Dinner     4\n",
       "  59        48.27  6.73    Male     No   Sat  Dinner     4\n",
       "  63        18.29  3.76    Male    Yes   Sat  Dinner     4\n",
       "  77        27.20  4.00    Male     No  Thur   Lunch     4\n",
       "  85        34.83  5.17  Female     No  Thur   Lunch     4\n",
       "  95        40.17  4.73    Male    Yes   Fri  Dinner     4\n",
       "  116       29.93  5.07    Male     No   Sun  Dinner     4\n",
       "  119       24.08  2.92  Female     No  Thur   Lunch     4\n",
       "  153       24.55  2.00    Male     No   Sun  Dinner     4\n",
       "  154       19.77  2.00    Male     No   Sun  Dinner     4\n",
       "  157       25.00  3.75  Female     No   Sun  Dinner     4\n",
       "  159       16.49  2.00    Male     No   Sun  Dinner     4\n",
       "  160       21.50  3.50    Male     No   Sun  Dinner     4\n",
       "  167       31.71  4.50    Male     No   Sun  Dinner     4\n",
       "  180       34.65  3.68    Male    Yes   Sun  Dinner     4\n",
       "  183       23.17  6.50    Male    Yes   Sun  Dinner     4\n",
       "  197       43.11  5.00  Female    Yes  Thur   Lunch     4\n",
       "  204       20.53  4.00    Male    Yes  Thur   Lunch     4\n",
       "  207       38.73  3.00    Male    Yes   Sat  Dinner     4\n",
       "  211       25.89  5.16    Male    Yes   Sat  Dinner     4\n",
       "  212       48.33  9.00    Male     No   Sat  Dinner     4\n",
       "  219       30.14  3.09  Female    Yes   Sat  Dinner     4\n",
       "  227       20.45  3.00    Male     No   Sat  Dinner     4\n",
       "  230       24.01  2.00    Male    Yes   Sat  Dinner     4),\n",
       " (5,      total_bill   tip     sex smoker   day    time  size\n",
       "  142       41.19  5.00    Male     No  Thur   Lunch     5\n",
       "  155       29.85  5.14  Female     No   Sun  Dinner     5\n",
       "  185       20.69  5.00    Male     No   Sun  Dinner     5\n",
       "  187       30.46  2.00    Male    Yes   Sun  Dinner     5\n",
       "  216       28.15  3.00    Male    Yes   Sat  Dinner     5),\n",
       " (6,      total_bill  tip     sex smoker   day    time  size\n",
       "  125       29.80  4.2  Female     No  Thur   Lunch     6\n",
       "  141       34.30  6.7    Male     No  Thur   Lunch     6\n",
       "  143       27.05  5.0  Female     No  Thur   Lunch     6\n",
       "  156       48.17  5.0    Male     No   Sun  Dinner     6)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group tips dataframe by size of table\n",
    "by_size = tips.groupby(\"size\")\n",
    "\n",
    "by_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we coerce it to a list, we see something interesting: \n",
    "# It's basically a list of tuples! \n",
    "# The first element is the \"category\" variable, the second\n",
    "# is a datafame. \n",
    "\n",
    "list(by_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female\n",
      "total_bill    18.056897\n",
      "tip            2.833448\n",
      "size           2.459770\n",
      "dtype: float64\n",
      "Male\n",
      "total_bill    20.744076\n",
      "tip            3.089618\n",
      "size           2.630573\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# We can iterate through the groupby just like we would a list of tuples!\n",
    "\n",
    "\n",
    "for sex,data in tips.groupby(\"sex\"):\n",
    "    print(sex)\n",
    "    print(data.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why do we groupby? \n",
    "\n",
    "We group by to perform _some_ operation on each group. To _map_ over the groups, applying a function to each element! \n",
    "\n",
    "Very often this function is itself an aggregation (reduction). We want to somehow aggregate each group into a value or set of values that _describe_ the group!\n",
    "\n",
    "How do we apply functions to each element of a groupby? We use a handy method called \".apply\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "Female    44.30\n",
       "Male      50.81\n",
       "dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the maximum bill by gender: \n",
    "#Will take a mini df, takes a col and then returns the max value in that col\n",
    "def max_bill(df):\n",
    "    return df.total_bill.max()\n",
    "\n",
    "tips.groupby(\"sex\").apply(max_bill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     16.99\n",
       "1     10.34\n",
       "2     21.01\n",
       "3     23.68\n",
       "4     24.59\n",
       "5     25.29\n",
       "6      8.77\n",
       "11    35.26\n",
       "14    14.83\n",
       "16    10.33\n",
       "Name: total_bill, dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Challenge: \n",
    "\n",
    "# Get the second largest bill by gender!\n",
    "# HINT: use sort_values and iloc!\n",
    "\n",
    "#This line of code is equivalent to the one below: tips.total_bill.sort_values()\n",
    "\n",
    "#Define a function, n_max_bill that takes parameters df and n(default 2)\n",
    "def n_max_bill(df, n=2):\n",
    "#Then return the total bill column, sorted and position\n",
    "    return df.total_bill.sort_values().iloc[-n]\n",
    "\n",
    "tips.grouby('sex').apply(n max_bill)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in Aggregations in groupby\n",
    "\n",
    "Many aggregation functions that exist on Series and DataFrames (mean, max, min, etc.) can be called directly via the groupby object: \n",
    "\n",
    "```python\n",
    "tips.groupby(\"sex\").max()\n",
    "tips.groupby(\"sex\").mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sex</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Fri</td>\n",
       "      <td>2.781111</td>\n",
       "      <td>2.693000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sat</td>\n",
       "      <td>2.801786</td>\n",
       "      <td>3.083898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sun</td>\n",
       "      <td>3.367222</td>\n",
       "      <td>3.220345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Thur</td>\n",
       "      <td>2.575625</td>\n",
       "      <td>2.980333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sex     Female      Male\n",
       "day                     \n",
       "Fri   2.781111  2.693000\n",
       "Sat   2.801786  3.083898\n",
       "Sun   3.367222  3.220345\n",
       "Thur  2.575625  2.980333"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Challenge: \n",
    "# What is the mean tip, per day, for male vs. female?\n",
    " # Hint: you will need to group by \"day\"\n",
    "    # in this function, then get the mean tip. \n",
    "\n",
    "def day_mean(df):\n",
    "    return df.groupby([\"sex\"]).tip.mean()\n",
    "  \n",
    "\n",
    "tips.groupby([\"day\"]).apply(day_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Multiple Groupby!\n",
    "\n",
    "That groupby induction that we just performed, it's quite a common use-case! So there's an even easier way to do it in Pandas. \n",
    "\n",
    "We can group by more than one column! \n",
    "\n",
    "For example the task we accomplished above could also be derived as: \n",
    "\n",
    "```python\n",
    "tips.groupby([\"sex\",\"day\"]).tip.mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Female', 'Fri'),      total_bill   tip     sex smoker  day    time  size\n",
       "  92         5.75  1.00  Female    Yes  Fri  Dinner     2\n",
       "  93        16.32  4.30  Female    Yes  Fri  Dinner     2\n",
       "  94        22.75  3.25  Female     No  Fri  Dinner     2\n",
       "  100       11.35  2.50  Female    Yes  Fri  Dinner     2\n",
       "  101       15.38  3.00  Female    Yes  Fri  Dinner     2\n",
       "  221       13.42  3.48  Female    Yes  Fri   Lunch     2\n",
       "  223       15.98  3.00  Female     No  Fri   Lunch     3\n",
       "  225       16.27  2.50  Female    Yes  Fri   Lunch     2\n",
       "  226       10.09  2.00  Female    Yes  Fri   Lunch     2),\n",
       " (('Female', 'Sat'),      total_bill   tip     sex smoker  day    time  size\n",
       "  21        20.29  2.75  Female     No  Sat  Dinner     2\n",
       "  22        15.77  2.23  Female     No  Sat  Dinner     2\n",
       "  29        19.65  3.00  Female     No  Sat  Dinner     2\n",
       "  32        15.06  3.00  Female     No  Sat  Dinner     2\n",
       "  33        20.69  2.45  Female     No  Sat  Dinner     4\n",
       "  37        16.93  3.07  Female     No  Sat  Dinner     3\n",
       "  57        26.41  1.50  Female     No  Sat  Dinner     2\n",
       "  66        16.45  2.47  Female     No  Sat  Dinner     2\n",
       "  67         3.07  1.00  Female    Yes  Sat  Dinner     1\n",
       "  71        17.07  3.00  Female     No  Sat  Dinner     3\n",
       "  72        26.86  3.14  Female    Yes  Sat  Dinner     2\n",
       "  73        25.28  5.00  Female    Yes  Sat  Dinner     2\n",
       "  74        14.73  2.20  Female     No  Sat  Dinner     2\n",
       "  102       44.30  2.50  Female    Yes  Sat  Dinner     3\n",
       "  103       22.42  3.48  Female    Yes  Sat  Dinner     2\n",
       "  104       20.92  4.08  Female     No  Sat  Dinner     2\n",
       "  109       14.31  4.00  Female    Yes  Sat  Dinner     2\n",
       "  111        7.25  1.00  Female     No  Sat  Dinner     1\n",
       "  168       10.59  1.61  Female    Yes  Sat  Dinner     2\n",
       "  169       10.63  2.00  Female    Yes  Sat  Dinner     2\n",
       "  209       12.76  2.23  Female    Yes  Sat  Dinner     2\n",
       "  213       13.27  2.50  Female    Yes  Sat  Dinner     2\n",
       "  214       28.17  6.50  Female    Yes  Sat  Dinner     3\n",
       "  215       12.90  1.10  Female    Yes  Sat  Dinner     2\n",
       "  219       30.14  3.09  Female    Yes  Sat  Dinner     4\n",
       "  229       22.12  2.88  Female    Yes  Sat  Dinner     2\n",
       "  238       35.83  4.67  Female     No  Sat  Dinner     3\n",
       "  240       27.18  2.00  Female    Yes  Sat  Dinner     2),\n",
       " (('Female', 'Sun'),      total_bill   tip     sex smoker  day    time  size\n",
       "  0         16.99  1.01  Female     No  Sun  Dinner     2\n",
       "  4         24.59  3.61  Female     No  Sun  Dinner     4\n",
       "  11        35.26  5.00  Female     No  Sun  Dinner     4\n",
       "  14        14.83  3.02  Female     No  Sun  Dinner     2\n",
       "  16        10.33  1.67  Female     No  Sun  Dinner     3\n",
       "  18        16.97  3.50  Female     No  Sun  Dinner     3\n",
       "  51        10.29  2.60  Female     No  Sun  Dinner     2\n",
       "  52        34.81  5.20  Female     No  Sun  Dinner     4\n",
       "  114       25.71  4.00  Female     No  Sun  Dinner     3\n",
       "  115       17.31  3.50  Female     No  Sun  Dinner     2\n",
       "  155       29.85  5.14  Female     No  Sun  Dinner     5\n",
       "  157       25.00  3.75  Female     No  Sun  Dinner     4\n",
       "  158       13.39  2.61  Female     No  Sun  Dinner     2\n",
       "  162       16.21  2.00  Female     No  Sun  Dinner     3\n",
       "  164       17.51  3.00  Female    Yes  Sun  Dinner     2\n",
       "  178        9.60  4.00  Female    Yes  Sun  Dinner     2\n",
       "  186       20.90  3.50  Female    Yes  Sun  Dinner     3\n",
       "  188       18.15  3.50  Female    Yes  Sun  Dinner     3),\n",
       " (('Female', 'Thur'),      total_bill   tip     sex smoker   day    time  size\n",
       "  82        10.07  1.83  Female     No  Thur   Lunch     1\n",
       "  85        34.83  5.17  Female     No  Thur   Lunch     4\n",
       "  117       10.65  1.50  Female     No  Thur   Lunch     2\n",
       "  118       12.43  1.80  Female     No  Thur   Lunch     2\n",
       "  119       24.08  2.92  Female     No  Thur   Lunch     4\n",
       "  121       13.42  1.68  Female     No  Thur   Lunch     2\n",
       "  124       12.48  2.52  Female     No  Thur   Lunch     2\n",
       "  125       29.80  4.20  Female     No  Thur   Lunch     6\n",
       "  127       14.52  2.00  Female     No  Thur   Lunch     2\n",
       "  128       11.38  2.00  Female     No  Thur   Lunch     2\n",
       "  131       20.27  2.83  Female     No  Thur   Lunch     2\n",
       "  132       11.17  1.50  Female     No  Thur   Lunch     2\n",
       "  133       12.26  2.00  Female     No  Thur   Lunch     2\n",
       "  134       18.26  3.25  Female     No  Thur   Lunch     2\n",
       "  135        8.51  1.25  Female     No  Thur   Lunch     2\n",
       "  136       10.33  2.00  Female     No  Thur   Lunch     2\n",
       "  137       14.15  2.00  Female     No  Thur   Lunch     2\n",
       "  139       13.16  2.75  Female     No  Thur   Lunch     2\n",
       "  140       17.47  3.50  Female     No  Thur   Lunch     2\n",
       "  143       27.05  5.00  Female     No  Thur   Lunch     6\n",
       "  144       16.43  2.30  Female     No  Thur   Lunch     2\n",
       "  145        8.35  1.50  Female     No  Thur   Lunch     2\n",
       "  146       18.64  1.36  Female     No  Thur   Lunch     3\n",
       "  147       11.87  1.63  Female     No  Thur   Lunch     2\n",
       "  191       19.81  4.19  Female    Yes  Thur   Lunch     2\n",
       "  197       43.11  5.00  Female    Yes  Thur   Lunch     4\n",
       "  198       13.00  2.00  Female    Yes  Thur   Lunch     2\n",
       "  201       12.74  2.01  Female    Yes  Thur   Lunch     2\n",
       "  202       13.00  2.00  Female    Yes  Thur   Lunch     2\n",
       "  203       16.40  2.50  Female    Yes  Thur   Lunch     2\n",
       "  205       16.47  3.23  Female    Yes  Thur   Lunch     3\n",
       "  243       18.78  3.00  Female     No  Thur  Dinner     2),\n",
       " (('Male', 'Fri'),      total_bill   tip   sex smoker  day    time  size\n",
       "  90        28.97  3.00  Male    Yes  Fri  Dinner     2\n",
       "  91        22.49  3.50  Male     No  Fri  Dinner     2\n",
       "  95        40.17  4.73  Male    Yes  Fri  Dinner     4\n",
       "  96        27.28  4.00  Male    Yes  Fri  Dinner     2\n",
       "  97        12.03  1.50  Male    Yes  Fri  Dinner     2\n",
       "  98        21.01  3.00  Male    Yes  Fri  Dinner     2\n",
       "  99        12.46  1.50  Male     No  Fri  Dinner     2\n",
       "  220       12.16  2.20  Male    Yes  Fri   Lunch     2\n",
       "  222        8.58  1.92  Male    Yes  Fri   Lunch     1\n",
       "  224       13.42  1.58  Male    Yes  Fri   Lunch     2),\n",
       " (('Male', 'Sat'),      total_bill    tip   sex smoker  day    time  size\n",
       "  19        20.65   3.35  Male     No  Sat  Dinner     3\n",
       "  20        17.92   4.08  Male     No  Sat  Dinner     2\n",
       "  23        39.42   7.58  Male     No  Sat  Dinner     4\n",
       "  24        19.82   3.18  Male     No  Sat  Dinner     2\n",
       "  25        17.81   2.34  Male     No  Sat  Dinner     4\n",
       "  26        13.37   2.00  Male     No  Sat  Dinner     2\n",
       "  27        12.69   2.00  Male     No  Sat  Dinner     2\n",
       "  28        21.70   4.30  Male     No  Sat  Dinner     2\n",
       "  30         9.55   1.45  Male     No  Sat  Dinner     2\n",
       "  31        18.35   2.50  Male     No  Sat  Dinner     4\n",
       "  34        17.78   3.27  Male     No  Sat  Dinner     2\n",
       "  35        24.06   3.60  Male     No  Sat  Dinner     3\n",
       "  36        16.31   2.00  Male     No  Sat  Dinner     3\n",
       "  38        18.69   2.31  Male     No  Sat  Dinner     3\n",
       "  39        31.27   5.00  Male     No  Sat  Dinner     3\n",
       "  40        16.04   2.24  Male     No  Sat  Dinner     3\n",
       "  56        38.01   3.00  Male    Yes  Sat  Dinner     4\n",
       "  58        11.24   1.76  Male    Yes  Sat  Dinner     2\n",
       "  59        48.27   6.73  Male     No  Sat  Dinner     4\n",
       "  60        20.29   3.21  Male    Yes  Sat  Dinner     2\n",
       "  61        13.81   2.00  Male    Yes  Sat  Dinner     2\n",
       "  62        11.02   1.98  Male    Yes  Sat  Dinner     2\n",
       "  63        18.29   3.76  Male    Yes  Sat  Dinner     4\n",
       "  64        17.59   2.64  Male     No  Sat  Dinner     3\n",
       "  65        20.08   3.15  Male     No  Sat  Dinner     3\n",
       "  68        20.23   2.01  Male     No  Sat  Dinner     2\n",
       "  69        15.01   2.09  Male    Yes  Sat  Dinner     2\n",
       "  70        12.02   1.97  Male     No  Sat  Dinner     2\n",
       "  75        10.51   1.25  Male     No  Sat  Dinner     2\n",
       "  76        17.92   3.08  Male    Yes  Sat  Dinner     2\n",
       "  105       15.36   1.64  Male    Yes  Sat  Dinner     2\n",
       "  106       20.49   4.06  Male    Yes  Sat  Dinner     2\n",
       "  107       25.21   4.29  Male    Yes  Sat  Dinner     2\n",
       "  108       18.24   3.76  Male     No  Sat  Dinner     2\n",
       "  110       14.00   3.00  Male     No  Sat  Dinner     2\n",
       "  170       50.81  10.00  Male    Yes  Sat  Dinner     3\n",
       "  171       15.81   3.16  Male    Yes  Sat  Dinner     2\n",
       "  206       26.59   3.41  Male    Yes  Sat  Dinner     3\n",
       "  207       38.73   3.00  Male    Yes  Sat  Dinner     4\n",
       "  208       24.27   2.03  Male    Yes  Sat  Dinner     2\n",
       "  210       30.06   2.00  Male    Yes  Sat  Dinner     3\n",
       "  211       25.89   5.16  Male    Yes  Sat  Dinner     4\n",
       "  212       48.33   9.00  Male     No  Sat  Dinner     4\n",
       "  216       28.15   3.00  Male    Yes  Sat  Dinner     5\n",
       "  217       11.59   1.50  Male    Yes  Sat  Dinner     2\n",
       "  218        7.74   1.44  Male    Yes  Sat  Dinner     2\n",
       "  227       20.45   3.00  Male     No  Sat  Dinner     4\n",
       "  228       13.28   2.72  Male     No  Sat  Dinner     2\n",
       "  230       24.01   2.00  Male    Yes  Sat  Dinner     4\n",
       "  231       15.69   3.00  Male    Yes  Sat  Dinner     3\n",
       "  232       11.61   3.39  Male     No  Sat  Dinner     2\n",
       "  233       10.77   1.47  Male     No  Sat  Dinner     2\n",
       "  234       15.53   3.00  Male    Yes  Sat  Dinner     2\n",
       "  235       10.07   1.25  Male     No  Sat  Dinner     2\n",
       "  236       12.60   1.00  Male    Yes  Sat  Dinner     2\n",
       "  237       32.83   1.17  Male    Yes  Sat  Dinner     2\n",
       "  239       29.03   5.92  Male     No  Sat  Dinner     3\n",
       "  241       22.67   2.00  Male    Yes  Sat  Dinner     2\n",
       "  242       17.82   1.75  Male     No  Sat  Dinner     2),\n",
       " (('Male', 'Sun'),      total_bill   tip   sex smoker  day    time  size\n",
       "  1         10.34  1.66  Male     No  Sun  Dinner     3\n",
       "  2         21.01  3.50  Male     No  Sun  Dinner     3\n",
       "  3         23.68  3.31  Male     No  Sun  Dinner     2\n",
       "  5         25.29  4.71  Male     No  Sun  Dinner     4\n",
       "  6          8.77  2.00  Male     No  Sun  Dinner     2\n",
       "  7         26.88  3.12  Male     No  Sun  Dinner     4\n",
       "  8         15.04  1.96  Male     No  Sun  Dinner     2\n",
       "  9         14.78  3.23  Male     No  Sun  Dinner     2\n",
       "  10        10.27  1.71  Male     No  Sun  Dinner     2\n",
       "  12        15.42  1.57  Male     No  Sun  Dinner     2\n",
       "  13        18.43  3.00  Male     No  Sun  Dinner     4\n",
       "  15        21.58  3.92  Male     No  Sun  Dinner     2\n",
       "  17        16.29  3.71  Male     No  Sun  Dinner     3\n",
       "  41        17.46  2.54  Male     No  Sun  Dinner     2\n",
       "  42        13.94  3.06  Male     No  Sun  Dinner     2\n",
       "  43         9.68  1.32  Male     No  Sun  Dinner     2\n",
       "  44        30.40  5.60  Male     No  Sun  Dinner     4\n",
       "  45        18.29  3.00  Male     No  Sun  Dinner     2\n",
       "  46        22.23  5.00  Male     No  Sun  Dinner     2\n",
       "  47        32.40  6.00  Male     No  Sun  Dinner     4\n",
       "  48        28.55  2.05  Male     No  Sun  Dinner     3\n",
       "  49        18.04  3.00  Male     No  Sun  Dinner     2\n",
       "  50        12.54  2.50  Male     No  Sun  Dinner     2\n",
       "  53         9.94  1.56  Male     No  Sun  Dinner     2\n",
       "  54        25.56  4.34  Male     No  Sun  Dinner     4\n",
       "  55        19.49  3.51  Male     No  Sun  Dinner     2\n",
       "  112       38.07  4.00  Male     No  Sun  Dinner     3\n",
       "  113       23.95  2.55  Male     No  Sun  Dinner     2\n",
       "  116       29.93  5.07  Male     No  Sun  Dinner     4\n",
       "  150       14.07  2.50  Male     No  Sun  Dinner     2\n",
       "  151       13.13  2.00  Male     No  Sun  Dinner     2\n",
       "  152       17.26  2.74  Male     No  Sun  Dinner     3\n",
       "  153       24.55  2.00  Male     No  Sun  Dinner     4\n",
       "  154       19.77  2.00  Male     No  Sun  Dinner     4\n",
       "  156       48.17  5.00  Male     No  Sun  Dinner     6\n",
       "  159       16.49  2.00  Male     No  Sun  Dinner     4\n",
       "  160       21.50  3.50  Male     No  Sun  Dinner     4\n",
       "  161       12.66  2.50  Male     No  Sun  Dinner     2\n",
       "  163       13.81  2.00  Male     No  Sun  Dinner     2\n",
       "  165       24.52  3.48  Male     No  Sun  Dinner     3\n",
       "  166       20.76  2.24  Male     No  Sun  Dinner     2\n",
       "  167       31.71  4.50  Male     No  Sun  Dinner     4\n",
       "  172        7.25  5.15  Male    Yes  Sun  Dinner     2\n",
       "  173       31.85  3.18  Male    Yes  Sun  Dinner     2\n",
       "  174       16.82  4.00  Male    Yes  Sun  Dinner     2\n",
       "  175       32.90  3.11  Male    Yes  Sun  Dinner     2\n",
       "  176       17.89  2.00  Male    Yes  Sun  Dinner     2\n",
       "  177       14.48  2.00  Male    Yes  Sun  Dinner     2\n",
       "  179       34.63  3.55  Male    Yes  Sun  Dinner     2\n",
       "  180       34.65  3.68  Male    Yes  Sun  Dinner     4\n",
       "  181       23.33  5.65  Male    Yes  Sun  Dinner     2\n",
       "  182       45.35  3.50  Male    Yes  Sun  Dinner     3\n",
       "  183       23.17  6.50  Male    Yes  Sun  Dinner     4\n",
       "  184       40.55  3.00  Male    Yes  Sun  Dinner     2\n",
       "  185       20.69  5.00  Male     No  Sun  Dinner     5\n",
       "  187       30.46  2.00  Male    Yes  Sun  Dinner     5\n",
       "  189       23.10  4.00  Male    Yes  Sun  Dinner     3\n",
       "  190       15.69  1.50  Male    Yes  Sun  Dinner     2),\n",
       " (('Male', 'Thur'),      total_bill   tip   sex smoker   day   time  size\n",
       "  77        27.20  4.00  Male     No  Thur  Lunch     4\n",
       "  78        22.76  3.00  Male     No  Thur  Lunch     2\n",
       "  79        17.29  2.71  Male     No  Thur  Lunch     2\n",
       "  80        19.44  3.00  Male    Yes  Thur  Lunch     2\n",
       "  81        16.66  3.40  Male     No  Thur  Lunch     2\n",
       "  83        32.68  5.00  Male    Yes  Thur  Lunch     2\n",
       "  84        15.98  2.03  Male     No  Thur  Lunch     2\n",
       "  86        13.03  2.00  Male     No  Thur  Lunch     2\n",
       "  87        18.28  4.00  Male     No  Thur  Lunch     2\n",
       "  88        24.71  5.85  Male     No  Thur  Lunch     2\n",
       "  89        21.16  3.00  Male     No  Thur  Lunch     2\n",
       "  120       11.69  2.31  Male     No  Thur  Lunch     2\n",
       "  122       14.26  2.50  Male     No  Thur  Lunch     2\n",
       "  123       15.95  2.00  Male     No  Thur  Lunch     2\n",
       "  126        8.52  1.48  Male     No  Thur  Lunch     2\n",
       "  129       22.82  2.18  Male     No  Thur  Lunch     3\n",
       "  130       19.08  1.50  Male     No  Thur  Lunch     2\n",
       "  138       16.00  2.00  Male    Yes  Thur  Lunch     2\n",
       "  141       34.30  6.70  Male     No  Thur  Lunch     6\n",
       "  142       41.19  5.00  Male     No  Thur  Lunch     5\n",
       "  148        9.78  1.73  Male     No  Thur  Lunch     2\n",
       "  149        7.51  2.00  Male     No  Thur  Lunch     2\n",
       "  192       28.44  2.56  Male    Yes  Thur  Lunch     2\n",
       "  193       15.48  2.02  Male    Yes  Thur  Lunch     2\n",
       "  194       16.58  4.00  Male    Yes  Thur  Lunch     2\n",
       "  195        7.56  1.44  Male     No  Thur  Lunch     2\n",
       "  196       10.34  2.00  Male    Yes  Thur  Lunch     2\n",
       "  199       13.51  2.00  Male    Yes  Thur  Lunch     2\n",
       "  200       18.71  4.00  Male    Yes  Thur  Lunch     3\n",
       "  204       20.53  4.00  Male    Yes  Thur  Lunch     4)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the structure of the multiple groupby!\n",
    "\n",
    "list(tips.groupby([\"sex\", \"day\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Combining dataframes\n",
    "\n",
    "There are many ways to combine various dataframes into a new one, extending in many ways what we already saw for operations on series. The main (among various) ways of doing this are: \n",
    "\n",
    "+ Concatenate: paste row-column-wise and taking action on NaNs\n",
    "    + This works more on the rectangular structure of the data \n",
    "+ Merge: combine dataframes using a common piece of information, e.g. a common column\n",
    "    + This works more as a database operation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Concatenate\n",
    "\n",
    "```python\n",
    "pd.concat([df1,df2,...] , axis = 0 , join = \"outer\", *keywds) \n",
    "```\n",
    "\n",
    "+ axis: 0 for pasting below, 1 for pasting on the side (order in list matters either way) \n",
    "\n",
    "What do you think will happen in the following case? \n",
    "\n",
    "```python\n",
    "df1 = pd.DataFrame({\"A\": pd.Series([1,2,3]), \"B\": pd.Series([4,5,6])})\n",
    "df2 = pd.DataFrame({\"A\": pd.Series([4]), \"C\": pd.Series([7])})\n",
    "df = pd.concat([df1,df2])\n",
    "print(df.loc[0])\n",
    "```\n",
    "\n",
    "The argument *join* can control the decisions to be taken in concatenating dataframes with key or index incompatibility. \n",
    "\n",
    "+ join: \"outer\" union, \"inner\" intersection \n",
    "\n",
    "What do you think will happen if we replace the concatenation step by: \n",
    "\n",
    "```python\n",
    "df = pd.concat([df1,df2], join = \"inner\")\n",
    "print(df.loc[0])\n",
    "```\n",
    "\n",
    "And what about this code? \n",
    "\n",
    "```python\n",
    "df1 = pd.DataFrame({\"A\": pd.Series([1,2,3]), \"B\": pd.Series([4,5,6])})\n",
    "df2 = pd.DataFrame({\"A\": pd.Series([4]), \"C\": pd.Series([7])})\n",
    "df = pd.concat([df1,df2],axis = 1,join = \"inner\")\n",
    "print(df[\"A\"])\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A    B    C\n",
      "0  1  4.0  NaN\n",
      "1  2  5.0  NaN\n",
      "2  3  6.0  NaN\n",
      "0  4  NaN  7.0\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({\"A\": pd.Series([1,2,3]), \"B\": pd.Series([4,5,6])})\n",
    "df2 = pd.DataFrame({\"A\": pd.Series([4]), \"C\": pd.Series([7])})\n",
    "df = pd.concat([df1,df2], axis=0, sort=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Merge\n",
    "\n",
    "The concept here is to connect two DataFrames on some common piece of information, e.g. a common column. The structure of the command is: \n",
    "\n",
    "```python\n",
    "pd.merge(leftdf, rightdf, how = \"inner\", on = , *keywds)  \n",
    "```\n",
    "\n",
    "+ \"on\" defines on what piece of information the DataFrames will merge, this can be a column name or a list thereof\n",
    "+ \"how\" is more versatile than \"join\" in pd.concat. There are four options:\n",
    "    + \"inner\": intersection of keys\n",
    "    + \"outer\": union of keys\n",
    "    + \"left\": use keys from left only\n",
    "    + \"right\": use keys from right only\n",
    "\n",
    "\n",
    "We revisit the previous construct and try now to merge instead. What do you think will happen below: (and what about the index labels now, compared to pd.concat??) \n",
    "\n",
    "```python\n",
    "df1 = pd.DataFrame({\"A\": pd.Series([1,2,3]), \"B\": pd.Series([4,5,6])})\n",
    "df2 = pd.DataFrame({\"A\": pd.Series([4]), \"C\": pd.Series([7])})\n",
    "df = pd.merge(df1,df2,on = \"A\", how = \"outer\")\n",
    "print(df)\n",
    "```\n",
    "and what will happen if \"how\" changes to each of the other options?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ebf216f02a4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"B\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"C\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"A\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"outer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({\"A\": pd.Series([1,2,3]), \"B\": pd.Series([4,5,6])})\n",
    "df2 = pd.DataFrame({\"A\": pd.Series([4]), \"C\": pd.Series([7])})\n",
    "df = pd.merge(df1,df2,on = \"A\", how = \"outer\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with non-rectangular data\n",
    "\n",
    "We mentioned in the beginning that Pandas is a library for working with rectangular data. \n",
    "\n",
    "What if your data is not rectangular? What does non-rectangular data look like? Very often our data might come in dictionaries. Imagine data about a \"tweet\". It might look like this: \n",
    "\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"screenname\": \"nandanrao\",\n",
    "    \"id_str\": \"928374987\",\n",
    "    \"text\": \"Woah, pandas is so much fun #worldrocked #jawdrop #win\",\n",
    "    \"hashtags\": [\"worldrocked\", \"jawdrop\", \"win\"]\n",
    "}\n",
    "```\n",
    "\n",
    "How would you fit this into a rectangular data format? Do the \"hashtags\" cause a problem? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8f76205c7b82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m            \"hashtags\": [\"datascience\", \"ml\", \"crossfit\"]}]\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_tweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# What is the \"hashtag\" column made of?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "raw_tweets = [{ \"screenname\": \"nandanrao\",\n",
    "          \"id_str\": \"928374987\",\n",
    "          \"text\": \"Woah, pandas is so much fun #worldrocked #jawdrop #ml\",\n",
    "          \"hashtags\": [\"worldrocked\", \"jawdrop\", \"ml\"]},\n",
    "          {\"screenname\": \"om\",\n",
    "           \"id_str\": \"98214039\",\n",
    "           \"text\": \"I eat linear models for breakfast #datascience #ml #crossfit\",\n",
    "           \"hashtags\": [\"datascience\", \"ml\", \"crossfit\"]}]\n",
    "\n",
    "tweets = pd.DataFrame(raw_tweets)\n",
    "\n",
    "# What is the \"hashtag\" column made of? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge keeps the data flat\n",
    "\n",
    "The correct way to use data such as this in pandas, data with nested lists, is to copy each tweet to multiple rows, one row for each hashtag. \n",
    "\n",
    "We can use \"merge\" to do this for us automatically if we put the data into two separate dataframes, one for the hashtags and one for the rest of the tweets. This is called \"normalized form\" and is often how you will find data if you get it from a SQL database: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-de3faa85c2c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_tweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"screenname\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"id_str\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "tweets = pd.DataFrame(raw_tweets, columns = [\"screenname\", \"id_str\", \"text\"])\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-25f64ba6a539>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 for tag in t['hashtags']]\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhashtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags_and_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'id_str'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hashtag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mhashtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "tags_and_ids = [(t['id_str'], tag) \n",
    "                for t in raw_tweets \n",
    "                for tag in t['hashtags']]\n",
    "\n",
    "hashtags = pd.DataFrame(tags_and_ids, columns = ['id_str', 'hashtag'])\n",
    "\n",
    "hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-331e4a29e0a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhashtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tweets' is not defined"
     ]
    }
   ],
   "source": [
    "df = tweets.merge(hashtags, how='left')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming project: Customer of the month\n",
    "\n",
    "\n",
    "- We have a list of prices for certain products given in the file \"supermarket_prices.csv\"\n",
    "- We have a list of transactions from certain customers in a period of a month given in \"supermarket_transactions.csv\"\n",
    "\n",
    "Calculate\n",
    "- How many items each client has purchased\n",
    "- How many items of each type each client has purchased\n",
    "- Calculate the total amount spent by each client\n",
    "- The company that provides the supermarket with bananas wishes to give a prize to the client that has spent the largest proportion of their spending on bananas. Who should win the prize? \n",
    "- A marketing company that works with the supermarket is interested to understand better the characteristics of the three people that have spent most of their spending on bananas. For each one of them report the other product that they have spent most of their remaining income on\n",
    "\n",
    "*Needless to say that eyeballing is OK for making sure your code makes sense, but will not result in full credits for the project. We want a fully automated code. To carry out the project successfully you need to use most the attributes and methods described earlier. The last one is a little tricky*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rkey'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-24b590386c28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0msupermarket_transactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupermarket_prices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lkey'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rkey'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   7332\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7333\u001b[0m             \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7334\u001b[0;31m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7335\u001b[0m         )\n\u001b[1;32m   7336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     )\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_rkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1772\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1773\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1774\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1776\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rkey'"
     ]
    }
   ],
   "source": [
    "#Import useful programmes\n",
    "import pandas as pd\n",
    "\n",
    "#Import data\n",
    "supermarket_prices = pd.read_csv(\"supermarket_prices.csv\")\n",
    "#supermarket_prices.head(5)\n",
    "\n",
    "supermarket_transactions = pd.read_csv(\"supermarket_transactions.csv\")\n",
    "#supermarket_transactions.head(5)\n",
    "\n",
    "#Items each client has purchased\n",
    "#supermarket_transactions.groupby(\"Buyer\").count().Quantity selects a column (series)\n",
    "#supermarket_transactions.groupby(\"Buyer\").count()['Quantity'] selects a column (series)\n",
    "#The following way selects a list of columns\n",
    "\n",
    "#items_per_client = supermarket_transactions.groupby(\"Buyer\").count()[['Quantity']]\n",
    "#items_per_client\n",
    "\n",
    "#items_perclient_pertype = supermarket_transactions.groupby([\"Buyer\", \"Product\"]).count()[['Quantity']]\n",
    "#items_perclient_pertype\n",
    "\n",
    "#WIP\n",
    "supermarket_transactions.merge(supermarket_prices, left_on='lkey', right_on='rkey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
